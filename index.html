<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Discovering Robotic Interaction Modes with Discrete Representation Learning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Anonymous author</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Anonymous author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Anonymous author</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Anonymous Institution Name<br>CoRL2024</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!--&lt;!&ndash; Teaser video&ndash;&gt;-->
<!--<section class="hero teaser">-->
<!--  <div class="container is-max-desktop">-->
<!--    <div class="hero-body">-->
<!--      <video poster="" id="tree" autoplay controls muted loop height="100%">-->
<!--        &lt;!&ndash; Your video here &ndash;&gt;-->
<!--        <source src="static/videos/banner_video.mp4"-->
<!--        type="video/mp4">-->
<!--      </video>-->
<!--      <h2 class="subtitle has-text-centered">-->
<!--        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. -->
<!--      </h2>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->
<!--&lt;!&ndash; End teaser video &ndash;&gt;-->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>

Human actions manipulating articulated objects, such as opening and
closing a drawer, can be categorized into multiple modalities we define as interac-
tion modes. Traditional robot learning approaches lack discrete representations of
these modes, which are crucial for empirical sampling and grounding. In this paper,
we present ActAIM2, which learns a discrete representation of robot manipulation
interaction modes in a purely unsupervised fashion, without the use of expert labels
or simulator-based privileged information. Utilizing novel data collection methods
involving simulator rollouts, ActAIM2 consists of an interaction mode selector
and a low-level action predictor. The selector generates discrete representations
of potential interaction modes with self-supervision, while the predictor outputs
corresponding action trajectories. Our method is validated through its success
rate in manipulating articulated objects and its robustness in sampling meaning-
ful actions from the discrete representation. Extensive experiments demonstrate
ActAIM2’s effectiveness in enhancing manipulability and generalizability over
baselines and ablation studies.

          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Method</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/figures/teaser_3.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          ActAIM2 identifies meaningful interaction modes such as open and close drawers from RGB-D images of articulated objects and robots.
          It represents these modes as discrete clusters of embeddings and trains a policy to generate control actions for each cluster-based interaction.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/figures/Fig2_3.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          GMM Model Selector The mode selector, a generative model, processes the differences between
the initial and final image visual embeddings as generated data, using the initial image embeddings as the
conditional variable.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/figures/fig3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Behavior Cloning Action Predictor Interaction mode ε is sampled from latent space
embedding from model selector. 5 Multiview RGBD observations from circled cameras are back-projected and
fused into a color point cloud to render novel views. Rendered image tokens and interaction mode token are
contacted and fed through a multiview transformer to predict action a = (p, R, q).
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/figures/mode_selector.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Mode Selector Decoder Architecture: The depicted architecture highlights the functionality
of the mode selector decoder, which is designed to process two primary inputs: multi-view RGBD images
O i = (O 0 i , O 1 i , O 2 i , O 3 i , O 4 i ), and the Mixture of Gaussian (GMM) variable x. It is important to note that x
can be represented as a multi-view feature vector, with our encoding approach preserving the separation of
multi-view channels. Initially, the multi-view RGBD images are passed through a pre-trained VGG-19 image
encoder to extract feature vectors for each view. Subsequently, these feature vectors, along with the GMM
variable x, are inputted into a joint transformer. This transformer, featuring four attention layers, is tasked with
producing the means and variances associated with the reconstructed task embedding ϵ.
      </h2>
    </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/figures/action_predictor.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Action Predictor Architecture: This model integrates multi-view observations directly as input,
sourced from predefined cameras within the scene. The process begins with the extraction of five RGBD images,
which are subsequently transformed into RGB point clouds. These are then subject to orthogonal projection
to generate five novel view images. Subsequently, these novel views are partitioned into smaller patches and
fed into a joint transformer. This transformer, characterized by four attention layers, integrates the sampled
task embedding derived from a Mixture of Gaussian distribution. The architecture of the joint transformer
encompasses eight attention layers, culminating in the production of a heatmap. This heatmap delineates the
action’s translation, the discretized rotation, and a binary variable indicating the gripper’s state—open or closed.
      </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/figures/mode_selector_training.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Training Process of the Mode Selector: This figure illustrates the training procedure of the mode selector,
mirroring the approach of a conditional generative model. It highlights the contrastive analysis between the
initial and final observations—the latter serving as the ground truth for task embedding—to delineate generated
data against the backdrop of encoded initial images as the conditional variable. The process involves inputting
both the generated task embedding data and the conditional variable into a 4-layer Residual network-based mode
encoder, which then predicts the categorical variable c. Following the Gaussian Mixture Variational Autoencoder
(GMVAE) methodology, the Gaussian Mixture Model (GMM) variable x is computed and introduced alongside
the conditional variable to the task embedding transformer decoder. This model is tasked with predicting the
reconstructed task embedding, sampled from the Gaussian distribution as outlined in the architecture of the
mode selector decoder, and calculating the reconstruction loss against the input ground truth data.
      </h2>
    </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/figures/mode_selector_inference.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Action Predictor Architecture: This model integrates multi-view observations directly as input,
sourced from predefined cameras within the scene. The process begins with the extraction of five RGBD images,
which are subsequently transformed into RGB point clouds. These are then subject to orthogonal projection
to generate five novel view images. Subsequently, these novel views are partitioned into smaller patches and
fed into a joint transformer. This transformer, characterized by four attention layers, integrates the sampled
task embedding derived from a Mixture of Gaussian distribution. The architecture of the joint transformer
encompasses eight attention layers, culminating in the production of a heatmap. This heatmap delineates the
action’s translation, the discretized rotation, and a binary variable indicating the gripper’s state—open or closed.
      </h2>
     </div>

  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">More Qualitative Results</h2>
      <div id="qual_0" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/figures/qual_0.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
        qual_0
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/figures/qual_1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
        qual_1
        </h2>
      </div>
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/figures/qual_2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
        qual_2
        </h2>
      </div>
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/figures/qual_3.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
        qual_3
        </h2>
      </div>
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/figures/qual_4.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
        qual_4
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!--&lt;!&ndash; Youtube video &ndash;&gt;-->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      &lt;!&ndash; Paper video. &ndash;&gt;-->
<!--      <h2 class="title is-3">Video Presentation</h2>-->
<!--      <div class="columns is-centered has-text-centered">-->
<!--        <div class="column is-four-fifths">-->
<!--          -->
<!--          <div class="publication-video">-->
<!--            &lt;!&ndash; Youtube embed code here &ndash;&gt;-->
<!--            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
<!--          </div>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->
<!--&lt;!&ndash; End youtube video &ndash;&gt;-->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="Video Results" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/video_154_0.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/video_154_1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_154_2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video4" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_8961_0.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video5" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_8961_1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video6" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_8961_2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video7" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_19898_0.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video8" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_19898_1.mp4"
            type="video/mp4">"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video9" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_19898_2.mp4"
            type="video/mp4">"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video10" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_20555_0.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video11" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_20555_1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video12" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_41083_0.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video13" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_41083_1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video14" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_41083_2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video15" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_102844_0.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video16" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/video_102844_1.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Appendix</h2>

      <iframe  src="static/pdfs/appendix.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
